# Nerva

**An LLM-native Operating System** â€” Where the LLM is the kernel, context is memory, tools are devices, and agents are applications.

[![TypeScript](https://img.shields.io/badge/TypeScript-5.3-blue.svg)](https://www.typescriptlang.org/)
[![Node.js](https://img.shields.io/badge/Node.js-18+-green.svg)](https://nodejs.org/)
[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](LICENSE)

---

## âš¡ Quickstart (< 5 minutes)

### Prerequisites

- **Node.js 18+** â€” [Download](https://nodejs.org/)
- **npm** or **pnpm** â€” Comes with Node.js
- **Ollama** â€” [Download](https://ollama.com/) for local LLM inference

### Installation

```bash
# Clone the repository
git clone https://github.com/nerva-project/nerva.git
cd nerva

# Install dependencies
pnpm install

# Build the project
pnpm build
```

### Configuration

```bash
# Pull a local model with Ollama (recommended: small & fast)
ollama pull qwen2.5:1.5b

# Copy the example environment file
cp .env.example .env

# Edit .env to set your model (default: qwen2.5:1.5b)
```

### Run Nerva

```bash
# Start the interactive shell
pnpm start

# Or run directly
node dist/packages/cli/index.js
```

### First Commands

```
â€º read package.json
â€º list files in src/
â€º search for "TODO" in the codebase
â€º help
```

**That's it!** You're now running Nerva.

---

## ğŸ¯ What is Nerva?

Nerva reimagines the operating system with an LLM at its core:

| Traditional OS | Nerva OS |
|----------------|----------|
| CPU executes code | LLM interprets intent |
| RAM stores data | Context window is memory |
| System calls | Tool invocations |
| Applications | Agents |
| Files | Knowledge |

### Core Concepts

- **Kernel** â€” The LLM that interprets user intent and orchestrates execution
- **Tools** â€” Capabilities like filesystem, web, and process execution
- **Agents** â€” Planner, Executor, and Summarizer that handle complex tasks
- **Memory** â€” Context management with automatic summarization

---

## What Can Nerva Do So Far?

### File Operations
```
read package.json
list files in src/
search for "TODO" in the codebase
write "hello world" to notes.txt
```

### Web Requests
```
fetch https://api.github.com/users/octocat
search the web for "TypeScript best practices"
```

### System Commands
```
run ls -la
execute npm --version
run git status
```

### Conversational AI
```
Hello, what can you do?
Help me understand this project
Explain how the kernel works
```

### Shell Shortcuts

| Shortcut | Action |
|----------|--------|
| `Ctrl+K` | Open command palette |
| `Ctrl+T` | Thread selector (multiple conversations) |
| `Ctrl+P` | Scratchpad for notes |
| `â†‘` / `â†“` | Browse command history |
| `?` | Help menu |
| `Ctrl+C` | Exit Nerva |

---

## ğŸ› ï¸ Features

### Interactive Shell

- **Input line** with streaming output
- **Command palette** (Ctrl+K) for quick actions
- **Thread management** (Ctrl+T) for multiple conversations
- **Scratchpad** (Ctrl+P) for notes
- **History** with persistence

### Built-in Tools

| Tool | Description |
|------|-------------|
| `fs` | File operations (read, write, list, search) |
| `web` | HTTP requests and web search |
| `process` | Execute system commands |

### Security

- **Sandboxed filesystem** â€” Only access allowed directories
- **Command whitelist** â€” Only approved commands can run
- **Rate limiting** â€” Protection against runaway requests
- **Secret redaction** â€” Sensitive data never logged

---

## âš™ï¸ Configuration

Configuration files live in `config/`:

```
config/
â”œâ”€â”€ models.yaml      # Model definitions
â”œâ”€â”€ tools.yaml       # Tool settings
â””â”€â”€ policies.yaml    # Security policies
```

### Environment Variables

| Variable | Description |
|----------|-------------|
| `OLLAMA_MODEL` | Ollama model name (e.g., `qwen2.5:1.5b`, `llama3:8b`) |
| `OLLAMA_HOST` | Ollama server URL (default: `http://localhost:11434`) |
| `NERVA_LOG_LEVEL` | Logging level (debug, info, warn, error) |
| `NERVA_CONFIG_DIR` | Custom config directory |

### Example: Change Default Model

Edit your `.env` file:

```bash
# Use a different Ollama model
OLLAMA_MODEL=llama3:8b

# Or use phi3 for even faster responses
OLLAMA_MODEL=phi3:mini
```

Available models: [Ollama Library](https://ollama.com/library)

### Example: Add Filesystem Root

Edit `config/policies.yaml`:

```yaml
filesystem:
  allow_roots:
    - ./workspace
    - ./scratch
    - /home/user/projects  # Add your directory
```

---

## ğŸ“– CLI Commands

```bash
nerva                    # Start the shell
nerva run                # Start with options
nerva run -l debug       # Enable debug logging
nerva run -c ./my-config # Use custom config directory

nerva config             # Show current configuration
nerva model list         # List available models
nerva model pull <name>  # Download a model

nerva help               # Show help
nerva version            # Show version
```

---

## ğŸ—ï¸ Project Structure

```
nerva/
â”œâ”€â”€ apps/
â”‚   â””â”€â”€ shell/           # Interactive TUI
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ kernel/          # Intent parsing, routing, orchestration
â”‚   â”œâ”€â”€ agents/          # Planner, Executor, Summarizer
â”‚   â”œâ”€â”€ tools/           # Filesystem, Web, Process tools
â”‚   â”œâ”€â”€ models/          # LLM adapters (Ollama, Local, Fallback)
â”‚   â”œâ”€â”€ memory/          # Context manager, Vector store, Logger
â”‚   â””â”€â”€ config/          # Configuration system
â”œâ”€â”€ packages/
â”‚   â””â”€â”€ cli/             # Command-line interface
â”œâ”€â”€ config/              # Default configuration files
â”œâ”€â”€ test/                # Unit and E2E tests
â””â”€â”€ docs/                # Documentation
```

---

## ğŸ§ª Development

### Run Tests

```bash
pnpm test              # Run all tests
pnpm test:unit         # Unit tests only
pnpm test:e2e          # End-to-end tests
pnpm test:coverage     # With coverage report
```

### Development Mode

```bash
pnpm dev               # Watch mode with auto-rebuild
```

### Linting & Formatting

```bash
pnpm lint              # Run ESLint
pnpm lint:fix          # Fix linting issues
pnpm format            # Format with Prettier
```

---

## ğŸ”§ Extending Nerva

### Add a Custom Tool

```typescript
// core/tools/my-tool.ts
import type { Tool, ToolResult } from "./types";

export class MyTool implements Tool {
  name = "my-tool";
  description = "Does something useful";
  parameters = {
    type: "object",
    properties: {
      input: { type: "string" }
    }
  };

  async execute(input: unknown): Promise<ToolResult> {
    // Implementation
    return {
      success: true,
      output: "Result",
      metadata: { duration_ms: 10 }
    };
  }
}
```

### Add a Custom Agent

See `core/agents/` for examples of Planner, Executor, and Summarizer agents.

---

## ğŸ“š Documentation

- [Architecture](docs/architecture.md) â€” System design and data flow
- [Build Plan](docs/PLAN.md) â€” Development roadmap
- [Prompt Templates](docs/prompts/) â€” LLM system prompts
- [Contributing](CONTRIBUTING.md) â€” How to contribute

---

## ğŸ¤ Contributing

Contributions are welcome! Please read [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

```bash
# Fork and clone
git clone https://github.com/YOUR_USERNAME/nerva.git

# Create a branch
git checkout -b feature/my-feature

# Make changes and test
pnpm test

# Submit a pull request
```

---

## ğŸ“„ License

Apache License 2.0 â€” See [LICENSE](LICENSE) for details.

---

## ğŸ™ Acknowledgments

- [Ollama](https://ollama.com/) â€” Local LLM server
- [Qwen](https://qwenlm.github.io/) â€” Efficient open-weight models
- [llama.cpp](https://github.com/ggerganov/llama.cpp) â€” Local model inference

---

<p align="center">
  <strong>Nerva</strong> â€” Rethinking the OS for the AI age
</p>

